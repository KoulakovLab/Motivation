function [action, Q] = actionAgent(X, Y, M, Mnet, MMAX, MMAX_GLOB, EPSILON)
%ACTIONAGENT Takes an action for an agent in the Four Demands task
%
%   Parameters
%   ==========
%   X            - number (X-coordinate of the agent)
%   Y            - number (Y-coordinate of the agent)
%   M            - vector (motivation to each resourse)
%   MNET         - DLNetwork (deep Q-model)
%   MMAX         - vector (maximum value of motivation to each resourse)
%   MMAX_GLOB    - number (global maximum value of motivation in simulation)
%   EPSILON      - double (fraction of random decisions)
%   ACTION       - number (next action generated by the model)
%   Q            - vector (action values)
%
%   Author
%   ======
%   Sergey Shuvaev, 2018-2021. sshuvaev@cshl.edu

%Convert the coordinate to Boolean format

C0 = zeros(1, 36);
C0(6 * (X - 1) + Y) = 1; %works faster than sub2ind
C0 = (C0 - 0.0278) / 0.1667;

%Compute the Q-values for each action

len = length(Mnet);
Mnet(1).setInput([C0, M / MMAX_GLOB * 10, max(MMAX(:)) / MMAX_GLOB * 10]);
for j = 2 : len - 1
    stepForward(Mnet, j);
end
Q = Mnet(len - 1).y * MMAX_GLOB;

%Pick an action

[~, action] = max(Q);
if rand < EPSILON
    action = randi(5);
end
